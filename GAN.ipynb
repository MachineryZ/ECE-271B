{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, img_size=28, latent_dim=100, lr=0.0002, n_cpu=8, n_epochs=200, sample_interval=400)\n",
      "[Epoch 0/200] [Batch 1/938] [D loss: 0.624303] [G loss: 0.691134]\n",
      "[Epoch 1/200] [Batch 1/938] [D loss: 0.270126] [G loss: 1.293734]\n",
      "[Epoch 2/200] [Batch 1/938] [D loss: 0.119772] [G loss: 3.257386]\n",
      "[Epoch 3/200] [Batch 1/938] [D loss: 0.364475] [G loss: 1.127154]\n",
      "[Epoch 4/200] [Batch 1/938] [D loss: 0.173469] [G loss: 2.032750]\n",
      "[Epoch 5/200] [Batch 1/938] [D loss: 0.212102] [G loss: 2.358183]\n",
      "[Epoch 6/200] [Batch 1/938] [D loss: 0.213352] [G loss: 2.740530]\n",
      "[Epoch 7/200] [Batch 1/938] [D loss: 0.296407] [G loss: 1.780870]\n",
      "[Epoch 8/200] [Batch 1/938] [D loss: 0.459536] [G loss: 0.954760]\n",
      "[Epoch 9/200] [Batch 1/938] [D loss: 0.379814] [G loss: 1.580950]\n",
      "[Epoch 10/200] [Batch 1/938] [D loss: 0.316028] [G loss: 1.576888]\n",
      "[Epoch 11/200] [Batch 1/938] [D loss: 0.364219] [G loss: 1.676588]\n",
      "[Epoch 12/200] [Batch 1/938] [D loss: 0.385076] [G loss: 1.573862]\n",
      "[Epoch 13/200] [Batch 1/938] [D loss: 0.362016] [G loss: 1.807720]\n",
      "[Epoch 14/200] [Batch 1/938] [D loss: 0.357435] [G loss: 1.640775]\n",
      "[Epoch 15/200] [Batch 1/938] [D loss: 0.418506] [G loss: 1.438737]\n",
      "[Epoch 16/200] [Batch 1/938] [D loss: 0.389163] [G loss: 1.894034]\n",
      "[Epoch 17/200] [Batch 1/938] [D loss: 0.343886] [G loss: 2.047412]\n",
      "[Epoch 18/200] [Batch 1/938] [D loss: 0.425535] [G loss: 2.427882]\n",
      "[Epoch 19/200] [Batch 1/938] [D loss: 0.383316] [G loss: 1.655736]\n",
      "[Epoch 20/200] [Batch 1/938] [D loss: 0.443531] [G loss: 1.678144]\n",
      "[Epoch 21/200] [Batch 1/938] [D loss: 0.421659] [G loss: 1.656838]\n",
      "[Epoch 22/200] [Batch 1/938] [D loss: 0.388068] [G loss: 1.862832]\n",
      "[Epoch 23/200] [Batch 1/938] [D loss: 0.463446] [G loss: 1.216868]\n",
      "[Epoch 24/200] [Batch 1/938] [D loss: 0.434716] [G loss: 2.206007]\n",
      "[Epoch 25/200] [Batch 1/938] [D loss: 0.379276] [G loss: 2.101013]\n",
      "[Epoch 26/200] [Batch 1/938] [D loss: 0.521706] [G loss: 1.109797]\n",
      "[Epoch 27/200] [Batch 1/938] [D loss: 0.342868] [G loss: 1.739030]\n",
      "[Epoch 28/200] [Batch 1/938] [D loss: 0.399722] [G loss: 1.994185]\n",
      "[Epoch 29/200] [Batch 1/938] [D loss: 0.336452] [G loss: 1.687071]\n",
      "[Epoch 30/200] [Batch 1/938] [D loss: 0.441279] [G loss: 1.465656]\n",
      "[Epoch 31/200] [Batch 1/938] [D loss: 0.415458] [G loss: 1.492314]\n",
      "[Epoch 32/200] [Batch 1/938] [D loss: 0.445891] [G loss: 1.582234]\n",
      "[Epoch 33/200] [Batch 1/938] [D loss: 0.496218] [G loss: 2.044803]\n",
      "[Epoch 34/200] [Batch 1/938] [D loss: 0.483239] [G loss: 1.347950]\n",
      "[Epoch 35/200] [Batch 1/938] [D loss: 0.396063] [G loss: 1.313201]\n",
      "[Epoch 36/200] [Batch 1/938] [D loss: 0.403449] [G loss: 1.513084]\n",
      "[Epoch 37/200] [Batch 1/938] [D loss: 0.424911] [G loss: 1.248223]\n",
      "[Epoch 38/200] [Batch 1/938] [D loss: 0.378375] [G loss: 1.443379]\n",
      "[Epoch 39/200] [Batch 1/938] [D loss: 0.465525] [G loss: 1.297722]\n",
      "[Epoch 40/200] [Batch 1/938] [D loss: 0.486679] [G loss: 1.575676]\n",
      "[Epoch 41/200] [Batch 1/938] [D loss: 0.448972] [G loss: 1.269711]\n",
      "[Epoch 42/200] [Batch 1/938] [D loss: 0.448943] [G loss: 1.486162]\n",
      "[Epoch 43/200] [Batch 1/938] [D loss: 0.469705] [G loss: 1.511473]\n",
      "[Epoch 44/200] [Batch 1/938] [D loss: 0.454497] [G loss: 1.341548]\n",
      "[Epoch 45/200] [Batch 1/938] [D loss: 0.406787] [G loss: 1.587923]\n",
      "[Epoch 46/200] [Batch 1/938] [D loss: 0.398862] [G loss: 1.447468]\n",
      "[Epoch 47/200] [Batch 1/938] [D loss: 0.427487] [G loss: 1.527436]\n",
      "[Epoch 48/200] [Batch 1/938] [D loss: 0.434881] [G loss: 1.562651]\n",
      "[Epoch 49/200] [Batch 1/938] [D loss: 0.489170] [G loss: 1.833383]\n",
      "[Epoch 50/200] [Batch 1/938] [D loss: 0.377800] [G loss: 1.224466]\n",
      "[Epoch 51/200] [Batch 1/938] [D loss: 0.425063] [G loss: 1.355255]\n",
      "[Epoch 52/200] [Batch 1/938] [D loss: 0.412896] [G loss: 1.568439]\n",
      "[Epoch 53/200] [Batch 1/938] [D loss: 0.367791] [G loss: 1.360143]\n",
      "[Epoch 54/200] [Batch 1/938] [D loss: 0.366013] [G loss: 1.861736]\n",
      "[Epoch 55/200] [Batch 1/938] [D loss: 0.507466] [G loss: 2.056540]\n",
      "[Epoch 56/200] [Batch 1/938] [D loss: 0.398493] [G loss: 1.710050]\n",
      "[Epoch 57/200] [Batch 1/938] [D loss: 0.407538] [G loss: 1.601956]\n",
      "[Epoch 58/200] [Batch 1/938] [D loss: 0.369491] [G loss: 1.483438]\n",
      "[Epoch 59/200] [Batch 1/938] [D loss: 0.465689] [G loss: 1.643017]\n",
      "[Epoch 60/200] [Batch 1/938] [D loss: 0.420933] [G loss: 1.275790]\n",
      "[Epoch 61/200] [Batch 1/938] [D loss: 0.408847] [G loss: 1.692317]\n",
      "[Epoch 62/200] [Batch 1/938] [D loss: 0.431042] [G loss: 1.520119]\n",
      "[Epoch 63/200] [Batch 1/938] [D loss: 0.409985] [G loss: 1.695907]\n",
      "[Epoch 64/200] [Batch 1/938] [D loss: 0.361986] [G loss: 2.023145]\n",
      "[Epoch 65/200] [Batch 1/938] [D loss: 0.516589] [G loss: 1.334665]\n",
      "[Epoch 66/200] [Batch 1/938] [D loss: 0.374915] [G loss: 1.821272]\n",
      "[Epoch 67/200] [Batch 1/938] [D loss: 0.340559] [G loss: 1.801544]\n",
      "[Epoch 68/200] [Batch 1/938] [D loss: 0.546138] [G loss: 0.996970]\n",
      "[Epoch 69/200] [Batch 1/938] [D loss: 0.420379] [G loss: 2.125943]\n",
      "[Epoch 70/200] [Batch 1/938] [D loss: 0.454798] [G loss: 1.478818]\n",
      "[Epoch 71/200] [Batch 1/938] [D loss: 0.390536] [G loss: 1.594714]\n",
      "[Epoch 72/200] [Batch 1/938] [D loss: 0.388155] [G loss: 1.648626]\n",
      "[Epoch 73/200] [Batch 1/938] [D loss: 0.502146] [G loss: 1.553434]\n",
      "[Epoch 74/200] [Batch 1/938] [D loss: 0.431998] [G loss: 2.048561]\n",
      "[Epoch 75/200] [Batch 1/938] [D loss: 0.556714] [G loss: 1.824558]\n",
      "[Epoch 76/200] [Batch 1/938] [D loss: 0.445618] [G loss: 1.728670]\n",
      "[Epoch 77/200] [Batch 1/938] [D loss: 0.376510] [G loss: 1.553397]\n",
      "[Epoch 78/200] [Batch 1/938] [D loss: 0.386050] [G loss: 1.538880]\n",
      "[Epoch 79/200] [Batch 1/938] [D loss: 0.373456] [G loss: 1.335855]\n",
      "[Epoch 80/200] [Batch 1/938] [D loss: 0.392105] [G loss: 1.959454]\n",
      "[Epoch 81/200] [Batch 1/938] [D loss: 0.402197] [G loss: 2.201425]\n",
      "[Epoch 82/200] [Batch 1/938] [D loss: 0.398240] [G loss: 1.726630]\n",
      "[Epoch 83/200] [Batch 1/938] [D loss: 0.371817] [G loss: 1.562546]\n",
      "[Epoch 84/200] [Batch 1/938] [D loss: 0.459878] [G loss: 1.513661]\n",
      "[Epoch 85/200] [Batch 1/938] [D loss: 0.353793] [G loss: 1.604158]\n",
      "[Epoch 86/200] [Batch 1/938] [D loss: 0.338011] [G loss: 1.510758]\n",
      "[Epoch 87/200] [Batch 1/938] [D loss: 0.382882] [G loss: 1.586323]\n",
      "[Epoch 88/200] [Batch 1/938] [D loss: 0.372744] [G loss: 1.488283]\n",
      "[Epoch 89/200] [Batch 1/938] [D loss: 0.322224] [G loss: 2.011411]\n",
      "[Epoch 90/200] [Batch 1/938] [D loss: 0.392395] [G loss: 1.417398]\n",
      "[Epoch 91/200] [Batch 1/938] [D loss: 0.431318] [G loss: 1.453231]\n",
      "[Epoch 92/200] [Batch 1/938] [D loss: 0.291420] [G loss: 1.835542]\n",
      "[Epoch 93/200] [Batch 1/938] [D loss: 0.403581] [G loss: 1.463515]\n",
      "[Epoch 94/200] [Batch 1/938] [D loss: 0.355496] [G loss: 1.898634]\n",
      "[Epoch 95/200] [Batch 1/938] [D loss: 0.425773] [G loss: 2.161093]\n",
      "[Epoch 96/200] [Batch 1/938] [D loss: 0.321600] [G loss: 1.747175]\n",
      "[Epoch 97/200] [Batch 1/938] [D loss: 0.474164] [G loss: 1.725372]\n",
      "[Epoch 98/200] [Batch 1/938] [D loss: 0.351116] [G loss: 1.837258]\n",
      "[Epoch 99/200] [Batch 1/938] [D loss: 0.378085] [G loss: 1.734797]\n",
      "[Epoch 100/200] [Batch 1/938] [D loss: 0.332315] [G loss: 1.614990]\n",
      "[Epoch 101/200] [Batch 1/938] [D loss: 0.398541] [G loss: 2.207427]\n",
      "[Epoch 102/200] [Batch 1/938] [D loss: 0.431346] [G loss: 1.836694]\n",
      "[Epoch 103/200] [Batch 1/938] [D loss: 0.318896] [G loss: 1.769363]\n",
      "[Epoch 104/200] [Batch 1/938] [D loss: 0.335076] [G loss: 1.667261]\n",
      "[Epoch 105/200] [Batch 1/938] [D loss: 0.275556] [G loss: 2.078949]\n",
      "[Epoch 106/200] [Batch 1/938] [D loss: 0.307832] [G loss: 1.816820]\n",
      "[Epoch 107/200] [Batch 1/938] [D loss: 0.361536] [G loss: 2.007158]\n",
      "[Epoch 108/200] [Batch 1/938] [D loss: 0.407299] [G loss: 1.745896]\n",
      "[Epoch 109/200] [Batch 1/938] [D loss: 0.484917] [G loss: 1.799964]\n",
      "[Epoch 110/200] [Batch 1/938] [D loss: 0.347453] [G loss: 1.700456]\n",
      "[Epoch 111/200] [Batch 1/938] [D loss: 0.350333] [G loss: 1.721186]\n",
      "[Epoch 112/200] [Batch 1/938] [D loss: 0.299552] [G loss: 1.899912]\n",
      "[Epoch 113/200] [Batch 1/938] [D loss: 0.306944] [G loss: 2.394035]\n",
      "[Epoch 114/200] [Batch 1/938] [D loss: 0.309410] [G loss: 1.898880]\n",
      "[Epoch 115/200] [Batch 1/938] [D loss: 0.320380] [G loss: 1.968268]\n",
      "[Epoch 116/200] [Batch 1/938] [D loss: 0.294420] [G loss: 1.770290]\n",
      "[Epoch 117/200] [Batch 1/938] [D loss: 0.372972] [G loss: 1.921610]\n",
      "[Epoch 118/200] [Batch 1/938] [D loss: 0.350147] [G loss: 1.653220]\n",
      "[Epoch 119/200] [Batch 1/938] [D loss: 0.358975] [G loss: 1.577307]\n",
      "[Epoch 120/200] [Batch 1/938] [D loss: 0.348417] [G loss: 1.843095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 121/200] [Batch 1/938] [D loss: 0.427335] [G loss: 1.655545]\n",
      "[Epoch 122/200] [Batch 1/938] [D loss: 0.405244] [G loss: 1.240759]\n",
      "[Epoch 123/200] [Batch 1/938] [D loss: 0.305318] [G loss: 1.570625]\n",
      "[Epoch 124/200] [Batch 1/938] [D loss: 0.327188] [G loss: 1.601640]\n",
      "[Epoch 125/200] [Batch 1/938] [D loss: 0.434158] [G loss: 1.519595]\n",
      "[Epoch 126/200] [Batch 1/938] [D loss: 0.382566] [G loss: 1.899565]\n",
      "[Epoch 127/200] [Batch 1/938] [D loss: 0.427655] [G loss: 1.670800]\n",
      "[Epoch 128/200] [Batch 1/938] [D loss: 0.392468] [G loss: 1.595762]\n",
      "[Epoch 129/200] [Batch 1/938] [D loss: 0.367864] [G loss: 1.908250]\n",
      "[Epoch 130/200] [Batch 1/938] [D loss: 0.352231] [G loss: 2.013667]\n",
      "[Epoch 131/200] [Batch 1/938] [D loss: 0.333026] [G loss: 1.557532]\n",
      "[Epoch 132/200] [Batch 1/938] [D loss: 0.264681] [G loss: 1.947615]\n",
      "[Epoch 133/200] [Batch 1/938] [D loss: 0.329481] [G loss: 1.714652]\n",
      "[Epoch 134/200] [Batch 1/938] [D loss: 0.323049] [G loss: 2.240488]\n",
      "[Epoch 135/200] [Batch 1/938] [D loss: 0.378110] [G loss: 1.566089]\n",
      "[Epoch 136/200] [Batch 1/938] [D loss: 0.325139] [G loss: 1.714844]\n",
      "[Epoch 137/200] [Batch 1/938] [D loss: 0.363859] [G loss: 1.496722]\n",
      "[Epoch 138/200] [Batch 1/938] [D loss: 0.303440] [G loss: 2.175270]\n",
      "[Epoch 139/200] [Batch 1/938] [D loss: 0.365757] [G loss: 2.264853]\n",
      "[Epoch 140/200] [Batch 1/938] [D loss: 0.294490] [G loss: 2.037938]\n",
      "[Epoch 141/200] [Batch 1/938] [D loss: 0.247591] [G loss: 1.879735]\n",
      "[Epoch 142/200] [Batch 1/938] [D loss: 0.313562] [G loss: 2.238159]\n",
      "[Epoch 143/200] [Batch 1/938] [D loss: 0.292322] [G loss: 1.492635]\n",
      "[Epoch 144/200] [Batch 1/938] [D loss: 0.278081] [G loss: 1.814591]\n",
      "[Epoch 145/200] [Batch 1/938] [D loss: 0.356354] [G loss: 2.019266]\n",
      "[Epoch 146/200] [Batch 1/938] [D loss: 0.255694] [G loss: 2.511339]\n",
      "[Epoch 147/200] [Batch 1/938] [D loss: 0.317773] [G loss: 1.975286]\n",
      "[Epoch 148/200] [Batch 1/938] [D loss: 0.310485] [G loss: 2.270608]\n",
      "[Epoch 149/200] [Batch 1/938] [D loss: 0.295088] [G loss: 2.008346]\n",
      "[Epoch 150/200] [Batch 1/938] [D loss: 0.333943] [G loss: 1.879143]\n",
      "[Epoch 151/200] [Batch 1/938] [D loss: 0.305938] [G loss: 1.542134]\n",
      "[Epoch 152/200] [Batch 1/938] [D loss: 0.331761] [G loss: 2.023486]\n",
      "[Epoch 153/200] [Batch 1/938] [D loss: 0.277933] [G loss: 1.954279]\n",
      "[Epoch 154/200] [Batch 1/938] [D loss: 0.279490] [G loss: 2.045965]\n",
      "[Epoch 155/200] [Batch 1/938] [D loss: 0.296660] [G loss: 2.095263]\n",
      "[Epoch 156/200] [Batch 1/938] [D loss: 0.282634] [G loss: 2.082814]\n",
      "[Epoch 157/200] [Batch 1/938] [D loss: 0.232600] [G loss: 1.988587]\n",
      "[Epoch 158/200] [Batch 1/938] [D loss: 0.271340] [G loss: 2.396759]\n",
      "[Epoch 159/200] [Batch 1/938] [D loss: 0.332433] [G loss: 2.062889]\n",
      "[Epoch 160/200] [Batch 1/938] [D loss: 0.266114] [G loss: 2.292311]\n",
      "[Epoch 161/200] [Batch 1/938] [D loss: 0.247677] [G loss: 2.430656]\n",
      "[Epoch 162/200] [Batch 1/938] [D loss: 0.288215] [G loss: 1.632550]\n",
      "[Epoch 163/200] [Batch 1/938] [D loss: 0.274832] [G loss: 1.981886]\n",
      "[Epoch 164/200] [Batch 1/938] [D loss: 0.281480] [G loss: 2.178649]\n",
      "[Epoch 165/200] [Batch 1/938] [D loss: 0.279439] [G loss: 2.059545]\n",
      "[Epoch 166/200] [Batch 1/938] [D loss: 0.314340] [G loss: 2.210657]\n",
      "[Epoch 167/200] [Batch 1/938] [D loss: 0.275576] [G loss: 2.078245]\n",
      "[Epoch 168/200] [Batch 1/938] [D loss: 0.348223] [G loss: 2.717026]\n",
      "[Epoch 169/200] [Batch 1/938] [D loss: 0.305188] [G loss: 1.792278]\n",
      "[Epoch 170/200] [Batch 1/938] [D loss: 0.309922] [G loss: 2.054598]\n",
      "[Epoch 171/200] [Batch 1/938] [D loss: 0.275620] [G loss: 2.153955]\n",
      "[Epoch 172/200] [Batch 1/938] [D loss: 0.358612] [G loss: 2.107085]\n",
      "[Epoch 173/200] [Batch 1/938] [D loss: 0.318373] [G loss: 2.151815]\n",
      "[Epoch 174/200] [Batch 1/938] [D loss: 0.264837] [G loss: 1.729351]\n",
      "[Epoch 175/200] [Batch 1/938] [D loss: 0.263319] [G loss: 2.596832]\n",
      "[Epoch 176/200] [Batch 1/938] [D loss: 0.323148] [G loss: 3.154070]\n",
      "[Epoch 177/200] [Batch 1/938] [D loss: 0.300500] [G loss: 2.273958]\n",
      "[Epoch 178/200] [Batch 1/938] [D loss: 0.309739] [G loss: 1.982678]\n",
      "[Epoch 179/200] [Batch 1/938] [D loss: 0.221933] [G loss: 2.367226]\n",
      "[Epoch 180/200] [Batch 1/938] [D loss: 0.286452] [G loss: 1.984347]\n",
      "[Epoch 181/200] [Batch 1/938] [D loss: 0.323217] [G loss: 2.311457]\n",
      "[Epoch 182/200] [Batch 1/938] [D loss: 0.368281] [G loss: 2.243649]\n",
      "[Epoch 183/200] [Batch 1/938] [D loss: 0.259079] [G loss: 2.165423]\n",
      "[Epoch 184/200] [Batch 1/938] [D loss: 0.304400] [G loss: 2.269411]\n",
      "[Epoch 185/200] [Batch 1/938] [D loss: 0.244708] [G loss: 2.072076]\n",
      "[Epoch 186/200] [Batch 1/938] [D loss: 0.264994] [G loss: 2.314624]\n",
      "[Epoch 187/200] [Batch 1/938] [D loss: 0.266324] [G loss: 2.418541]\n",
      "[Epoch 188/200] [Batch 1/938] [D loss: 0.334639] [G loss: 2.385089]\n",
      "[Epoch 189/200] [Batch 1/938] [D loss: 0.282805] [G loss: 2.540348]\n",
      "[Epoch 190/200] [Batch 1/938] [D loss: 0.230905] [G loss: 2.231253]\n",
      "[Epoch 191/200] [Batch 1/938] [D loss: 0.260817] [G loss: 1.963450]\n",
      "[Epoch 192/200] [Batch 1/938] [D loss: 0.289749] [G loss: 2.292847]\n",
      "[Epoch 193/200] [Batch 1/938] [D loss: 0.198715] [G loss: 2.163165]\n",
      "[Epoch 194/200] [Batch 1/938] [D loss: 0.330397] [G loss: 2.302278]\n",
      "[Epoch 195/200] [Batch 1/938] [D loss: 0.265269] [G loss: 2.177719]\n",
      "[Epoch 196/200] [Batch 1/938] [D loss: 0.273297] [G loss: 2.342894]\n",
      "[Epoch 197/200] [Batch 1/938] [D loss: 0.216524] [G loss: 2.377189]\n",
      "[Epoch 198/200] [Batch 1/938] [D loss: 0.230210] [G loss: 2.273592]\n",
      "[Epoch 199/200] [Batch 1/938] [D loss: 0.209108] [G loss: 2.518166]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval betwen image samples\")\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 2048),\n",
    "            nn.Linear(2048, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity\n",
    "\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs(\"/home/zhizuo/271B/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"/home/zhizuo/271B/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "D_loss = np.zeros(opt.n_epochs)\n",
    "G_loss = np.zeros(opt.n_epochs)\n",
    "for epoch in range(opt.n_epochs):\n",
    "    \n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        \n",
    "        D_loss[epoch] += d_loss\n",
    "        G_loss[epoch] += g_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        if i == 1:\n",
    "            print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        #if batches_done % opt.sample_interval == 0:\n",
    "        if (epoch + 1) % 50 == 0 and epoch >= 1 and i == 1:\n",
    "            save_image(gen_imgs.data[:25], \"images/GAN_%d.png\" % epoch, nrow=5, normalize=True)\n",
    "    D_loss[epoch] /= len(dataloader)\n",
    "    G_loss[epoch] /= len(dataloader)\n",
    "    \n",
    "    if epoch == opt.n_epochs - 1:\n",
    "        torch.save(generator.state_dict(), \n",
    "                  '/home/zhizuo/271B/GAN_g_128_256_512_1024_1536_.pkl')\n",
    "        torch.save(discriminator.state_dict(), \n",
    "                  '/home/zhizuo/271B/GAN_d_512_256_.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "opt.n_epochs = 200\n",
    "x = np.zeros(opt.n_epochs)\n",
    "for i in range(opt.n_epochs):\n",
    "    x[i] = i\n",
    "plt.figure()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"GAN\")\n",
    "plt.plot(x, D_loss,color='green', label = 'D_loss')\n",
    "plt.plot(x, G_loss,color='blue', label = 'G_loss')\n",
    "plt.xlim(0,opt.n_epochs)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
